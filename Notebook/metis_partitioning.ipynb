{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU1W0EYX7P56"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../..')\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "import metis\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p7SQy96t7iKU",
        "outputId": "2d4f2d2b-c1cd-47dd-fd1f-1fb85758daac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ampligraph\n",
            "  Downloading ampligraph-2.0.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.3/178.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (1.22.4)\n",
            "Requirement already satisfied: pytest>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (7.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (1.2.2)\n",
            "Collecting deap>=1.2.2 (from ampligraph)\n",
            "  Downloading deap-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (1.2.0)\n",
            "Requirement already satisfied: tqdm>=4.23.4 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (1.5.3)\n",
            "Collecting sphinx==5.0.2 (from ampligraph)\n",
            "  Downloading Sphinx-5.0.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting myst-parser==0.18.0 (from ampligraph)\n",
            "  Downloading myst_parser-0.18.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docutils<0.18 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (0.16)\n",
            "Collecting sphinx-rtd-theme==1.0.0 (from ampligraph)\n",
            "  Downloading sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-bibtex==2.4.2 (from ampligraph)\n",
            "  Downloading sphinxcontrib_bibtex-2.4.2-py3-none-any.whl (39 kB)\n",
            "Collecting beautifultable>=0.7.0 (from ampligraph)\n",
            "  Downloading beautifultable-1.1.0-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: pyyaml>=3.13 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (6.0)\n",
            "Collecting rdflib>=4.2.2 (from ampligraph)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (3.1)\n",
            "Collecting flake8>=3.7.7 (from ampligraph)\n",
            "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=36 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (67.7.2)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (3.7.1)\n",
            "Collecting docopt==0.6.2 (from ampligraph)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting schema==0.7.5 (from ampligraph)\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from myst-parser==0.18.0->ampligraph) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from myst-parser==0.18.0->ampligraph) (2.2.0)\n",
            "Collecting mdit-py-plugins~=0.3.0 (from myst-parser==0.18.0->ampligraph)\n",
            "  Downloading mdit_py_plugins-0.3.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from myst-parser==0.18.0->ampligraph) (4.5.0)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema==0.7.5->ampligraph) (0.6.0.post1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (2.14.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (2.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (23.1)\n",
            "Collecting pybtex>=0.24 (from sphinxcontrib-bibtex==2.4.2->ampligraph)\n",
            "  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybtex-docutils>=1.0.0 (from sphinxcontrib-bibtex==2.4.2->ampligraph)\n",
            "  Downloading pybtex_docutils-1.0.2-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from beautifultable>=0.7.0->ampligraph) (0.2.6)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8>=3.7.7->ampligraph)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.11.0,>=2.10.0 (from flake8>=3.7.7->ampligraph)\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyflakes<3.1.0,>=3.0.0 (from flake8>=3.7.7->ampligraph)\n",
            "  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.1->ampligraph) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph) (2.0.1)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=4.2.2->ampligraph)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->ampligraph) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=4.2.2->ampligraph) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->myst-parser==0.18.0->ampligraph) (2.1.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=1.0.0->myst-parser==0.18.0->ampligraph) (0.1.2)\n",
            "Collecting latexcodec>=1.0.4 (from pybtex>=0.24->sphinxcontrib-bibtex==2.4.2->ampligraph)\n",
            "  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph) (3.4)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=91e6e3156289e3c659ec077a6c9de4f067acc9eb101f3170fdccb76e2c304080\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, schema, pyflakes, pycodestyle, mccabe, latexcodec, isodate, deap, beautifultable, sphinx, rdflib, pybtex, mdit-py-plugins, flake8, sphinx-rtd-theme, pybtex-docutils, myst-parser, sphinxcontrib-bibtex, ampligraph\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "Successfully installed ampligraph-2.0.0 beautifultable-1.1.0 deap-1.3.3 docopt-0.6.2 flake8-6.0.0 isodate-0.6.1 latexcodec-2.0.1 mccabe-0.7.0 mdit-py-plugins-0.3.5 myst-parser-0.18.0 pybtex-0.24.0 pybtex-docutils-1.0.2 pycodestyle-2.10.0 pyflakes-3.0.1 rdflib-6.3.2 schema-0.7.5 sphinx-5.0.2 sphinx-rtd-theme-1.0.0 sphinxcontrib-bibtex-2.4.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install ampligraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZ-Db1nE4b4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8SdvipR7cFt"
      },
      "outputs": [],
      "source": [
        "\n",
        "import ampligraph\n",
        "# Benchmark datasets are under ampligraph.datasets module\n",
        "from ampligraph.datasets import load_fb15k_237\n",
        "# load fb15k-237 dataset\n",
        "dataset = load_fb15k_237()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Chargement des triplets du jeu de données FB15K\n",
        "df = pd.read_csv('/content/sample_data/train.txt', sep='\\t', header=None, names=['head', 'relation', 'tail'])\n",
        "\n",
        "# Nombre de partitions souhaitées\n",
        "k = 12\n",
        "\n",
        "# Permutation aléatoire des indices des triplets\n",
        "indices = np.random.permutation(df.index)\n",
        "\n",
        "# Division des indices en k sous-ensembles\n",
        "partitions = np.array_split(indices, k)\n",
        "\n",
        "# Affichage des résultats\n",
        "for i, part in enumerate(partitions):\n",
        "    print(f\"Partition {i}: {part}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlnyVX--4dbl",
        "outputId": "d94dfc03-6344-4a7c-b350-8ca1c2923389"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partition 0: [135270 441371 417815 ... 362105  55590 188286]\n",
            "Partition 1: [271755 260857 295085 ... 134638  38575 367773]\n",
            "Partition 2: [177724  56483 371811 ... 334130  66133 273337]\n",
            "Partition 3: [407720 234485 245221 ... 367460 474035  97967]\n",
            "Partition 4: [ 39567 162298 393583 ... 279164 237342 192048]\n",
            "Partition 5: [ 39515 144227  18215 ... 198349  13110  58682]\n",
            "Partition 6: [381491  17740 464330 ...  61763  14288 162684]\n",
            "Partition 7: [255060 430182 192680 ... 216193 386644 376704]\n",
            "Partition 8: [421724 408010 163775 ... 206965 261252 236475]\n",
            "Partition 9: [ 78265 255080 192315 ... 167763  62483  49107]\n",
            "Partition 10: [389137  49711 218398 ... 242556 266836 371366]\n",
            "Partition 11: [217884  84227  46464 ... 284112 180430 452251]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd34rz4R7zeM",
        "outputId": "e7e29df8-93a0-4975-97a1-8a60964ce942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "29/29 [==============================] - 18s 625ms/step - loss: 36581.9766\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 23s 782ms/step - loss: 22528.6367\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 13s 452ms/step - loss: 17284.1270\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 13s 464ms/step - loss: 14601.8623\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 14s 467ms/step - loss: 12988.7441\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 13s 462ms/step - loss: 11921.1309\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 14s 491ms/step - loss: 11167.2803\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 14s 468ms/step - loss: 10608.0420\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 14s 468ms/step - loss: 10177.2725\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 15s 512ms/step - loss: 9836.7529\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb01e7d5b40>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ray\n",
        "\n",
        "ray.init()\n",
        "\n",
        "@ray.remote\n",
        "def my_function(x):\n",
        "    return x * 2\n",
        "\n",
        "results = ray.get([my_function.remote(i) for i in range(10)])\n",
        "print(results)\n",
        "# Import the KGE model\n",
        "from ampligraph.latent_features import ScoringBasedEmbeddingModel\n",
        "\n",
        "# you can continue training from where you left after restoring the model\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./transe_train_logs')\n",
        "\n",
        "# create the model with transe scoring function\n",
        "model = ScoringBasedEmbeddingModel(eta=5,\n",
        "                                   k=300,\n",
        "                                   scoring_type='TransE')\n",
        "\n",
        "# you can either use optimizers/regularizers/loss/initializers with default values or you can\n",
        "# import it and customize the hyperparameters and pass it to compile\n",
        "\n",
        "# Let's create an adam optimizer with customized learning rate =0.005\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "# Let's compile the model with self_advarsarial loss of default parameters\n",
        "model.compile(optimizer=adam, loss='self_adversarial')\n",
        "\n",
        "# fit the model to data.\n",
        "model.fit(dataset['train'],\n",
        "             batch_size=10000,\n",
        "             epochs=10,\n",
        "             callbacks=[tensorboard_callback])\n",
        "\n",
        "# the training can be visualised using the following command:\n",
        "# tensorboard --logdir='./transe_train_logs' --port=8891\n",
        "# open the browser and go to the following URL: http://127.0.0.1:8891/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opixrApy8o0_",
        "outputId": "0ecb5779-6dfc-4a70-d97c-c8e3ad0921a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-2.2747788, -2.092898 , -2.3081005, -4.3056355, -4.6757336],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = model.predict(dataset['test'][:5],\n",
        "                       batch_size=100)\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4V0WF2lu13R",
        "outputId": "3dea4b5c-2572-43b0-d4d7-5169f33ad5f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "206/206 [==============================] - 681s 3s/step\n",
            "MR: 347.97634308640767\n",
            "MRR: 0.19130546822000338\n",
            "hits@3: 0.20623348664252864\n",
            "hits@10: 0.3211664546433115\n",
            "hits@5: 0.24992660730012722\n"
          ]
        }
      ],
      "source": [
        "# evaluate on the test set\n",
        "ranks = model.evaluate(dataset['test'],\n",
        "                       batch_size=100,\n",
        "                       corrupt_side='s,o', # corrupt both subject and object\n",
        "                       use_filter={'train':dataset['train'], # Filter to be used for evaluation\n",
        "                                   'valid':dataset['valid'],\n",
        "                                   'test':dataset['test']}\n",
        "                       )\n",
        "\n",
        "# import the evaluation metrics\n",
        "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
        "\n",
        "print('MR:', mr_score(ranks))\n",
        "print('MRR:', mrr_score(ranks))\n",
        "print('hits@3:', hits_at_n_score(ranks, 3))\n",
        "print('hits@10:', hits_at_n_score(ranks, 10))\n",
        "print('hits@5:', hits_at_n_score(ranks, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ1t6uy58ucq",
        "outputId": "eac67499-8f8c-4704-8dd3-64e086d19bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "206/206 [==============================] - 593s 3s/step\n",
            "MR: 477.0276445836187\n",
            "MRR: 0.08879523476957402\n",
            "hits@3: 0.1277032977786476\n",
            "hits@10: 0.2402632351502104\n",
            "hits@5: 0.17195909580193758\n"
          ]
        }
      ],
      "source": [
        "# evaluate on the test set\n",
        "ranks = model.evaluate(dataset['test'],     # test set\n",
        "                       batch_size=100,      # evaluation batch size\n",
        "                       corrupt_side='s,o'   # sides to corrupt for scoring and ranking\n",
        "                       )\n",
        "\n",
        "# import the evaluation metrics\n",
        "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
        "\n",
        "# convert the ranks to milliseconds/step\n",
        "ranks_ms = ranks * 1000\n",
        "\n",
        "print('MR:', mr_score(ranks))\n",
        "print('MRR:', mrr_score(ranks))\n",
        "print('hits@3:', hits_at_n_score(ranks, 3))\n",
        "print('hits@10:', hits_at_n_score(ranks, 10))\n",
        "print('hits@5:', hits_at_n_score(ranks, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iWTni0pFhmg",
        "outputId": "8a77e5ad-c1fc-4534-ca23-2ce083dcf26f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "206/206 [==============================] - 329s 2s/step\n",
            "MR: 271.89137880418826\n",
            "MRR: 0.12984180159028205\n",
            "hits@3: 0.20334670711419905\n",
            "hits@10: 0.34978960759369804\n",
            "hits@5: 0.2644583618749388\n"
          ]
        }
      ],
      "source": [
        "# evaluate on the test set\n",
        "ranks = model.evaluate(dataset['test'],\n",
        "                       batch_size=100,\n",
        "                       corrupt_side='o' # corrupt only the object\n",
        "                       )\n",
        "\n",
        "# import the evaluation metrics\n",
        "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
        "\n",
        "print('MR:', mr_score(ranks))\n",
        "print('MRR:', mrr_score(ranks))\n",
        "print('hits@3:', hits_at_n_score(ranks, 3))\n",
        "print('hits@10:', hits_at_n_score(ranks, 10))\n",
        "print('hits@5:', hits_at_n_score(ranks, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE_gnTZJ3vtC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../..')\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4iSdciCzVKma",
        "outputId": "63e34f39-6381-47de-fca6-87b72463a184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ampligraph\n",
            "  Downloading ampligraph-2.0.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.3/178.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (1.22.4)\n",
            "Requirement already satisfied: pytest>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (7.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (1.2.2)\n",
            "Collecting deap>=1.2.2 (from ampligraph)\n",
            "  Downloading deap-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (1.2.0)\n",
            "Requirement already satisfied: tqdm>=4.23.4 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (1.5.3)\n",
            "Collecting sphinx==5.0.2 (from ampligraph)\n",
            "  Downloading Sphinx-5.0.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting myst-parser==0.18.0 (from ampligraph)\n",
            "  Downloading myst_parser-0.18.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docutils<0.18 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (0.16)\n",
            "Collecting sphinx-rtd-theme==1.0.0 (from ampligraph)\n",
            "  Downloading sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-bibtex==2.4.2 (from ampligraph)\n",
            "  Downloading sphinxcontrib_bibtex-2.4.2-py3-none-any.whl (39 kB)\n",
            "Collecting beautifultable>=0.7.0 (from ampligraph)\n",
            "  Downloading beautifultable-1.1.0-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: pyyaml>=3.13 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (6.0)\n",
            "Collecting rdflib>=4.2.2 (from ampligraph)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (3.1)\n",
            "Collecting flake8>=3.7.7 (from ampligraph)\n",
            "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=36 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (67.7.2)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.10/dist-packages (from ampligraph) (3.7.1)\n",
            "Collecting docopt==0.6.2 (from ampligraph)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting schema==0.7.5 (from ampligraph)\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from myst-parser==0.18.0->ampligraph) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from myst-parser==0.18.0->ampligraph) (2.2.0)\n",
            "Collecting mdit-py-plugins~=0.3.0 (from myst-parser==0.18.0->ampligraph)\n",
            "  Downloading mdit_py_plugins-0.3.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from myst-parser==0.18.0->ampligraph) (4.5.0)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema==0.7.5->ampligraph) (0.6.0.post1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (2.14.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (2.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx==5.0.2->ampligraph) (23.1)\n",
            "Collecting pybtex>=0.24 (from sphinxcontrib-bibtex==2.4.2->ampligraph)\n",
            "  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybtex-docutils>=1.0.0 (from sphinxcontrib-bibtex==2.4.2->ampligraph)\n",
            "  Downloading pybtex_docutils-1.0.2-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from beautifultable>=0.7.0->ampligraph) (0.2.6)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8>=3.7.7->ampligraph)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.11.0,>=2.10.0 (from flake8>=3.7.7->ampligraph)\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyflakes<3.1.0,>=3.0.0 (from flake8>=3.7.7->ampligraph)\n",
            "  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->ampligraph) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.1->ampligraph) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=3.5.1->ampligraph) (2.0.1)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib>=4.2.2->ampligraph)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->ampligraph) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=4.2.2->ampligraph) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->myst-parser==0.18.0->ampligraph) (2.1.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=1.0.0->myst-parser==0.18.0->ampligraph) (0.1.2)\n",
            "Collecting latexcodec>=1.0.4 (from pybtex>=0.24->sphinxcontrib-bibtex==2.4.2->ampligraph)\n",
            "  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx==5.0.2->ampligraph) (3.4)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=ef4247da1e9a29bee4945b58ae9a324f19a1237f55206948f70393e696af2300\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, schema, pyflakes, pycodestyle, mccabe, latexcodec, isodate, deap, beautifultable, sphinx, rdflib, pybtex, mdit-py-plugins, flake8, sphinx-rtd-theme, pybtex-docutils, myst-parser, sphinxcontrib-bibtex, ampligraph\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "Successfully installed ampligraph-2.0.0 beautifultable-1.1.0 deap-1.3.3 docopt-0.6.2 flake8-6.0.0 isodate-0.6.1 latexcodec-2.0.1 mccabe-0.7.0 mdit-py-plugins-0.3.5 myst-parser-0.18.0 pybtex-0.24.0 pybtex-docutils-1.0.2 pycodestyle-2.10.0 pyflakes-3.0.1 rdflib-6.3.2 schema-0.7.5 sphinx-5.0.2 sphinx-rtd-theme-1.0.0 sphinxcontrib-bibtex-2.4.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install ampligraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wGS6nzj3z67"
      },
      "outputs": [],
      "source": [
        "import ampligraph\n",
        "# load the dataset\n",
        "from ampligraph.datasets import load_wn18rr\n",
        "X = load_wn18rr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq4bBGf839_3"
      },
      "outputs": [],
      "source": [
        "# Import the models from ampligraph.compat\n",
        "# AmpliGraph 2 APIs support TransE, DistMult, ComplEx, HolE\n",
        "\n",
        "from ampligraph.compat import DistMult\n",
        "\n",
        "model = DistMult(batches_count=10, seed=0, epochs=200, k=350, eta=10,\n",
        "                    # Use adam optimizer with learning rate 1e-3\n",
        "                    optimizer='adam', optimizer_params={'lr':1e-3},\n",
        "                    # Use multiclass_nll loss\n",
        "                    loss='multiclass_nll', loss_params={},\n",
        "                    # Use L3 regularizer with regularizer weight 1e-3\n",
        "                    regularizer='LP', regularizer_params={'p':3, 'lambda':1e-3},\n",
        "                    # Enable stdout messages (set to false if you don't want to display)\n",
        "                    verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI6915Fl4eYd"
      },
      "outputs": [],
      "source": [
        "# Create the filter\n",
        "filter = np.concatenate((X['train'], X['valid'][::10], X['test']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U8XbOip4ila",
        "outputId": "34740d8b-51ef-492b-d76a-8303334c0595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "73 triples containing invalid keys skipped!\n",
            "\n",
            "13473 triples containing invalid keys skipped!\n",
            "4/4 [==============================] - 19s 5s/step\n",
            "\n",
            "73 triples containing invalid keys skipped!\n",
            "\n",
            "13473 triples containing invalid keys skipped!\n",
            "4/4 [==============================] - 18s 4s/step\n",
            "\n",
            "73 triples containing invalid keys skipped!\n",
            "\n",
            "13473 triples containing invalid keys skipped!\n",
            "4/4 [==============================] - 17s 4s/step\n",
            "\n",
            "73 triples containing invalid keys skipped!\n",
            "\n",
            "13473 triples containing invalid keys skipped!\n",
            "4/4 [==============================] - 17s 4s/step\n",
            "\n",
            "73 triples containing invalid keys skipped!\n",
            "\n",
            "13473 triples containing invalid keys skipped!\n",
            "4/4 [==============================] - 18s 4s/step\n",
            "\n",
            "73 triples containing invalid keys skipped!\n",
            "\n",
            "13473 triples containing invalid keys skipped!\n",
            "4/4 [==============================] - 17s 4s/step\n",
            "\n",
            "73 triples containing invalid keys skipped!\n",
            "\n",
            "13473 triples containing invalid keys skipped!\n",
            "4/4 [==============================] - 26s 7s/step\n",
            "\n",
            "73 triples containing invalid keys skipped!\n",
            "\n",
            "13473 triples containing invalid keys skipped!\n",
            "4/4 [==============================] - 15s 4s/step\n",
            "Restoring model weights from the end of the best epoch: 60.\n",
            "Epoch 160: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Fit the model on training and validation set\n",
        "model.fit(X['train'][::2],\n",
        "          early_stopping = True,\n",
        "          early_stopping_params = \\\n",
        "                  {\n",
        "                      'x_valid': X['valid'][::10],  # validation set\n",
        "                      'criteria':'hits@10',         # Uses hits10 criteria for early stopping\n",
        "                      'burn_in': 20,                # early stopping kicks in after 100 epochs\n",
        "                      'check_interval':20,          # validates every 20th epoch\n",
        "                      'stop_interval':5,            # stops if 5 successive validation checks are bad.\n",
        "                      'x_filter': filter,           # Use filter for filtering out positives\n",
        "                      'corruption_entities':'all',  # corrupt using all entities\n",
        "                      'corrupt_side':'s'            # corrupt only subject\n",
        "                  }\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4viwYQRf8Iz2",
        "outputId": "ec11c013-e302-4425-89ba-691958c1d04a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['06845599', '_member_of_domain_usage', '03754979'],\n",
              "       ['00789448', '_verb_group', '01062739']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_test = X['test']\n",
        "X_test[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP4v1Rka8QpZ",
        "outputId": "e7125e38-3b1a-4a09-bed7-638f0bab9d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1 triples containing invalid keys skipped!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.3586604], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Score assigned to unseen triples\n",
        "model.predict(X_test[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU18dBkO8W5I",
        "outputId": "4aa626d0-8ee6-40c9-b846-4116c0f0fcd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding size:  350\n",
            "\n",
            " Embedding vectors: \n",
            "[[ 0.12910752  0.15135074 -0.16565813  0.11561505 -0.04820582  0.19148798\n",
            "   0.13974549  0.19822668  0.16901898  0.11203824  0.19388743  0.1476582\n",
            "  -0.2067023  -0.17670077  0.17454751 -0.21035734  0.18862414  0.03869277\n",
            "  -0.20593068 -0.15297332 -0.17412762  0.18418746  0.07722044  0.08032427\n",
            "  -0.09058186 -0.16871965 -0.1742022  -0.12594631 -0.21976699  0.16816202\n",
            "   0.21994954  0.1627388   0.16893199 -0.16982768 -0.1631837  -0.17969781\n",
            "   0.18598314 -0.19630529 -0.13223849 -0.20012033 -0.15605195 -0.21406525\n",
            "  -0.18576413 -0.20493993 -0.10127719 -0.2058874   0.20073095  0.18321975\n",
            "   0.19793671  0.21260428 -0.16347584  0.14388329  0.03916905 -0.20124558\n",
            "  -0.19271863  0.13540003 -0.2005674   0.13259536  0.14816919 -0.19516236\n",
            "   0.20309976  0.17451021  0.21679515  0.19556521 -0.19746925  0.16150354\n",
            "   0.1861482   0.18452062 -0.17845432 -0.18181342  0.20852149  0.19513547\n",
            "  -0.19364342 -0.18842155  0.08736203  0.15385468 -0.21077445  0.21433188\n",
            "   0.20052266 -0.19650796 -0.20176232 -0.14044812  0.19355096  0.18280292\n",
            "   0.12261239 -0.21089983  0.19222885 -0.21335723  0.00507165  0.06011625\n",
            "  -0.20874505 -0.1781835  -0.17712079 -0.18054543  0.18196575 -0.20637588\n",
            "  -0.20129958  0.13492654  0.20278838 -0.05733727 -0.21837015 -0.14727214\n",
            "   0.1965627  -0.16192429  0.15486489  0.16145222  0.22222091 -0.1990531\n",
            "   0.19918567 -0.20663899  0.0310202  -0.22139446  0.02306733 -0.17799138\n",
            "  -0.18707038 -0.19643286  0.17732506 -0.03833051 -0.10749912  0.21056426\n",
            "   0.20357677 -0.20463862  0.16451481  0.11982099  0.19678135 -0.20745024\n",
            "  -0.12337291 -0.20289704  0.18849517 -0.2017181  -0.20641448  0.20536068\n",
            "   0.08633373  0.21127494  0.15757382  0.18296109  0.11326236 -0.18517628\n",
            "  -0.18101549  0.20645954 -0.20413208  0.21451026 -0.01977899 -0.21903548\n",
            "   0.19170028 -0.07930787  0.20738551  0.00571232  0.21449108  0.21495108\n",
            "   0.19752909 -0.13603471 -0.19095927  0.20836124 -0.17368574  0.00801856\n",
            "  -0.15935926 -0.2114367  -0.16445465  0.10776287 -0.21010438 -0.01579343\n",
            "   0.18920597  0.10555309  0.14850408 -0.1139506  -0.21912463 -0.1739948\n",
            "  -0.20140824  0.19286604  0.19624461 -0.21199717  0.21804632  0.18515784\n",
            "   0.01330956  0.17252025  0.17591807 -0.21352708  0.19003083  0.18830104\n",
            "   0.09929466 -0.19634883  0.21122438 -0.13637766 -0.15812442  0.19342184\n",
            "  -0.20737292 -0.01201579 -0.08153786  0.19076282 -0.10222708 -0.20028386\n",
            "   0.14864254 -0.1805455   0.11205043  0.17065774  0.2274764   0.18873888\n",
            "  -0.08281803  0.15937799 -0.20137799 -0.21982126 -0.19584031  0.15146706\n",
            "  -0.22743508  0.1583969   0.20080943 -0.20229246  0.16739139  0.18046835\n",
            "   0.19959344  0.18999135  0.16951069 -0.1997494   0.1795101  -0.20213641\n",
            "   0.1724858  -0.19134517  0.16964775  0.19061208 -0.1506614   0.17021444\n",
            "   0.21514454  0.22280034  0.09321295  0.17395602 -0.18582322  0.21536313\n",
            "  -0.19394265  0.12133168 -0.20608252  0.04273316 -0.14995831  0.20609725\n",
            "   0.17604107 -0.08659421 -0.17621768  0.15923831  0.18376528  0.19642752\n",
            "  -0.19824655 -0.18030037 -0.18341824  0.03856679  0.21158254 -0.0671672\n",
            "   0.21416268 -0.10148489 -0.06762722  0.19698332 -0.17114402  0.17977987\n",
            "   0.19779563  0.13003407 -0.15319999  0.19153124 -0.1803899  -0.14385477\n",
            "   0.10693218 -0.16343774  0.11698558 -0.20641364  0.163139    0.12552734\n",
            "   0.18876284 -0.06455015 -0.17353316 -0.11722476 -0.16358152 -0.20003417\n",
            "  -0.15727235 -0.1993507   0.17401817 -0.19213338  0.16786663  0.17018017\n",
            "  -0.19521151  0.15119419 -0.20494354 -0.18686254  0.17853622 -0.15820946\n",
            "   0.09283091 -0.20115648  0.2065782  -0.18520907  0.21353228  0.21124147\n",
            "  -0.19668251 -0.14025049  0.19903821 -0.2140638   0.17128421 -0.18103243\n",
            "   0.20498888  0.19731495  0.20436017 -0.2052113   0.17534375  0.20128176\n",
            "  -0.01168702  0.19961795 -0.19185226  0.01807199 -0.19954102  0.20899548\n",
            "  -0.20077778  0.03866841  0.20207915  0.15752807  0.19637297  0.21810941\n",
            "   0.17356224 -0.15393995  0.17850758 -0.21245569 -0.1452069   0.16172035\n",
            "   0.23198469  0.07556748 -0.11798026 -0.20602827  0.16859916  0.20356426\n",
            "  -0.04746453 -0.20839041  0.20359911  0.12688321  0.15109654 -0.19443092\n",
            "  -0.18367967  0.1940449   0.05849932  0.20345582 -0.07829335  0.18870151\n",
            "   0.004064   -0.17522013 -0.20252259  0.21698475  0.10547794 -0.1655496\n",
            "   0.20438673 -0.18578774 -0.21106808  0.12774163 -0.21755826  0.16553313\n",
            "   0.16137007 -0.08778842]\n",
            " [ 0.25396597  0.11078095  0.27856252 -0.1645296   0.19704475  0.21298254\n",
            "   0.27468145  0.27136034  0.2660702   0.24559486  0.08337185 -0.19229968\n",
            "  -0.20743975  0.31787887  0.30606085  0.24231254 -0.21693183  0.31122354\n",
            "   0.2430475  -0.19564867 -0.22933394  0.0651719   0.20996812 -0.2830618\n",
            "   0.254312   -0.10540482 -0.32004023  0.2709373  -0.31201193 -0.10604469\n",
            "  -0.32738027 -0.27658215 -0.3072764  -0.20494962 -0.23954257  0.29640087\n",
            "   0.2994145   0.20851356 -0.301578    0.3130265   0.23631065 -0.22133605\n",
            "   0.12079634  0.25554067  0.28159374  0.05696368 -0.31581     0.32265228\n",
            "  -0.22013949 -0.26790783 -0.13954908  0.23392206  0.23756924 -0.07269767\n",
            "  -0.272849    0.3110228  -0.23606503  0.28751978 -0.27415463 -0.2749494\n",
            "  -0.1303499   0.13165691 -0.3109773   0.21802852 -0.30960286  0.12858143\n",
            "  -0.23222066 -0.18875073 -0.26045594  0.29126412 -0.27754873  0.08631713\n",
            "  -0.26768214 -0.09386424  0.00106061 -0.12209293 -0.1921834   0.23526946\n",
            "   0.25238082  0.29348168  0.2056191  -0.28683066 -0.21858613 -0.20037742\n",
            "   0.23208803  0.07930047 -0.13388628  0.0825384  -0.25170627  0.30814096\n",
            "  -0.2987138   0.2181395  -0.26446772  0.20687456  0.32928824 -0.000838\n",
            "  -0.21806812 -0.2767513   0.26149184 -0.29219428  0.26128778 -0.0202664\n",
            "   0.31028226  0.25127915 -0.23969626 -0.29795438 -0.18798526 -0.30800697\n",
            "  -0.23469037  0.2734085  -0.22580636  0.11320692  0.2302968  -0.30091888\n",
            "  -0.10120955 -0.14192687  0.27195165  0.26228434 -0.21199204 -0.21105225\n",
            "   0.22818029  0.3045787   0.24874334  0.1908154  -0.2731187   0.31065658\n",
            "  -0.23091131  0.26093474  0.2937185   0.18862042  0.13045356 -0.31667587\n",
            "   0.23599656  0.23847502 -0.31254268  0.0334775   0.32729593  0.20882255\n",
            "  -0.31425926  0.3285141  -0.26980716  0.2723661  -0.20515455 -0.32487547\n",
            "   0.25459498 -0.20526254  0.27420276  0.03674905 -0.03863233  0.17096677\n",
            "  -0.26683125  0.12837136 -0.117517    0.28919202 -0.25314462 -0.14666402\n",
            "  -0.23573586  0.19159673  0.1938556  -0.29921213  0.04762783 -0.14663188\n",
            "  -0.2377019  -0.2923837   0.2623445  -0.17054723  0.17652066 -0.24900098\n",
            "   0.3211468   0.29281205 -0.23336953  0.2285364   0.26025233 -0.07600955\n",
            "   0.22824994 -0.07193221 -0.32106426  0.28027764  0.28862223 -0.26638794\n",
            "   0.19930385 -0.27403572  0.025891    0.2312084  -0.04919783  0.19156066\n",
            "  -0.26002756  0.20080383  0.25284222 -0.265415   -0.26358813  0.3181134\n",
            "  -0.2624275   0.24837533 -0.13001454  0.30605903 -0.14479901  0.21145867\n",
            "  -0.2656968   0.31031644 -0.15367486 -0.25368103  0.29097745 -0.18700619\n",
            "   0.18448524  0.29934448 -0.30116907 -0.31577986  0.23209031  0.19184516\n",
            "   0.02249702  0.07477911  0.2524721  -0.15624318  0.28781372 -0.25129017\n",
            "  -0.12812419  0.30619377 -0.32605106 -0.27030835 -0.29957512 -0.14824346\n",
            "   0.26033968 -0.28786725  0.21777256 -0.0195423  -0.09851165  0.23910311\n",
            "  -0.2938735  -0.2892443   0.22727677 -0.24812286 -0.25563377  0.3262602\n",
            "  -0.2975062   0.17026573  0.22343722  0.2720219   0.08774608 -0.1757786\n",
            "  -0.22853309 -0.26273856 -0.03124831  0.10722306  0.29659575  0.13075262\n",
            "  -0.17543     0.15859173 -0.2212841  -0.13496426 -0.30188164  0.2474355\n",
            "   0.24623007  0.02032497 -0.26905325 -0.24877349 -0.25541866  0.26760736\n",
            "   0.19297433 -0.30759174 -0.2560922   0.04461345  0.2467292   0.27445742\n",
            "  -0.15551236  0.2788949   0.2991241  -0.22430739 -0.31244907 -0.16823901\n",
            "   0.21260029 -0.2734835  -0.1721784   0.08033928  0.0086304  -0.03081232\n",
            "  -0.15745884 -0.01108607 -0.28442535  0.20853387 -0.2376849   0.26797917\n",
            "  -0.15813121 -0.24333608  0.31197304 -0.27330872 -0.30656075 -0.31426054\n",
            "   0.26185548 -0.07504161  0.31098145 -0.2874961  -0.10131149 -0.29783964\n",
            "  -0.12750764 -0.25249657  0.18799274  0.08306421 -0.14913929  0.30087954\n",
            "   0.13093121  0.288847   -0.3273693  -0.2298449   0.28142107  0.31040356\n",
            "   0.27491727  0.24458708 -0.31222183 -0.3104814  -0.24534856 -0.00474762\n",
            "   0.10845409  0.19594924  0.30869937 -0.24678129  0.21792279 -0.2980627\n",
            "  -0.02943929  0.2655891   0.30069485  0.29103023  0.22704239  0.29391897\n",
            "  -0.21243688  0.16746452  0.30846205  0.24022515  0.09147476 -0.03240093\n",
            "  -0.18773738 -0.12403478 -0.00515333 -0.2513988  -0.2668325  -0.23890829\n",
            "   0.28756967  0.22797038 -0.2863212  -0.26534542  0.22704239  0.25368983\n",
            "   0.29767787  0.30197415  0.28562385 -0.24764143 -0.1691822  -0.280931\n",
            "   0.19634454 -0.19599631]]\n"
          ]
        }
      ],
      "source": [
        "# Get embedding of entities\n",
        "embed = model.get_embeddings(['11647131','02518161'], embedding_type='entity')\n",
        "print('Embedding size: ', embed.shape[1])\n",
        "# Notice that the embedding size for ComplEx is double\n",
        "# compared to the k specified when initializing the model,\n",
        "# since ComplEx embeddings live in the space of complex numbers.\n",
        "print('\\n Embedding vectors: ')\n",
        "print(embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfMCO-v-8gIt",
        "outputId": "856c4e99-00f4-41aa-b2d9-6025c434d4e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33117, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# get the entity and relation mappings to emb matrix\n",
        "ent_to_idx, rel_to_idx = model.get_hyperparameter_dict()\n",
        "len(ent_to_idx), len(rel_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao_GzuPL4Ujt",
        "outputId": "b0796f00-b65a-4ba5-e4a6-115c75e917da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "676 triples containing invalid keys skipped!\n",
            "\n",
            "13473 triples containing invalid keys skipped!\n",
            "2249/2249 [==============================] - 240s 107ms/step\n",
            "MR: 9828.000222419929\n",
            "MRR: 0.2954941397023313\n",
            "hits@3: 0.3047153024911032\n",
            "hits@10: 0.3374110320284697\n",
            "hits@5: 0.3193950177935943\n"
          ]
        }
      ],
      "source": [
        "# import the evaluate_performance API from compat module\n",
        "from ampligraph.compat import evaluate_performance\n",
        "ranks = evaluate_performance(X_test, model, filter_triples=filter, corrupt_side='s,o', verbose=True)\n",
        "\n",
        "# import the evaluation metrics\n",
        "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score, mr_score\n",
        "\n",
        "print('MR:', mr_score(ranks))\n",
        "print('MRR:', mrr_score(ranks))\n",
        "print('hits@3:', hits_at_n_score(ranks, 3))\n",
        "print('hits@10:', hits_at_n_score(ranks, 10))\n",
        "print('hits@5:', hits_at_n_score(ranks, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQK3mToDLdib"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "import numpy as np\n",
        "import ampligraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "wxzMty66LXAd",
        "outputId": "e6d8ffc8-b1c3-4a97-baf4-517a16cc7e34"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5297b8710a5a>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Here we have specified the path of the input file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# you can also load using default dataloaders load_fb15k_237() and pass numpy array inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m partitioned_model.fit(PATH_TO_DATASET + 'wn18RR/train.txt',\n\u001b[0m\u001b[1;32m     15\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                       \u001b[0mpartitioning_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# set flag to partition the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ampligraph/latent_features/models/ScoringBasedEmbeddingModel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, initial_epoch, validation_batch_size, validation_corrupt_side, validation_freq, validation_burn_in, validation_filter, validation_entities_subset, partitioning_k, focusE, focusE_params)\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;31m# create data handler for the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             self.data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m    732\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ampligraph/datasets/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, model, batch_size, dataset_type, epochs, initial_epoch, use_indexer, use_filter, partitioning_k)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m# use graph data loader by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             self._adapter = GraphDataLoader(\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNoBackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ampligraph/datasets/graph_data_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, batch_size, dataset_type, backend, root_directory, use_indexer, verbose, remap, name, parent, in_memory, use_filter)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         self.batch_iterator = self.get_batch_generator(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ampligraph/datasets/graph_data_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, data_source, dataset_type)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_indexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 self.mapper = DataIndexer(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ampligraph/datasets/source_identifier.py\u001b[0m in \u001b[0;36mload_csv\u001b[0;34m(data_source, chunk_size, sep, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mEither\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlazy\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m     data = pd.read_csv(\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your/path/to/dataset/wn18RR/train.txt'"
          ]
        }
      ],
      "source": [
        "# Import the KGE model\n",
        "from ampligraph.latent_features import ScoringBasedEmbeddingModel\n",
        "\n",
        "PATH_TO_DATASET = 'your/path/to/dataset/'\n",
        "\n",
        "# create the model with transe scoring function\n",
        "partitioned_model = ScoringBasedEmbeddingModel(eta=2,\n",
        "                                               k=50,\n",
        "                                               scoring_type='TransE')\n",
        "partitioned_model.compile(optimizer='adam', loss='multiclass_nll')\n",
        "\n",
        "# Here we have specified the path of the input file\n",
        "# you can also load using default dataloaders load_fb15k_237() and pass numpy array inputs\n",
        "partitioned_model.fit(PATH_TO_DATASET + 'wn18RR/train.txt',\n",
        "                      batch_size=10000,\n",
        "                      partitioning_k=3, # set flag to partition the inputs\n",
        "                      epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('../..')\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "2WsguZtI3qfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ampligraph\n",
        "# Benchmark datasets are under ampligraph.datasets module\n",
        "from ampligraph.datasets import load_fb15k_237\n",
        "# load fb15k-237 dataset\n",
        "dataset = load_fb15k_237()"
      ],
      "metadata": {
        "id": "TktgCJAB3whi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the KGE model\n",
        "from ampligraph.latent_features import ScoringBasedEmbeddingModel\n",
        "\n",
        "# you can continue training from where you left after restoring the model\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./transe_train_logs')\n",
        "\n",
        "# create the model with transe scoring function\n",
        "model = ScoringBasedEmbeddingModel(eta=5,\n",
        "                                   k=300,\n",
        "                                   scoring_type='TransE')\n",
        "\n",
        "# you can either use optimizers/regularizers/loss/initializers with default values or you can\n",
        "# import it and customize the hyperparameters and pass it to compile\n",
        "\n",
        "# Let's create an adam optimizer with customized learning rate =0.005\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.004295)\n",
        "# Let's compile the model with self_advarsarial loss of default parameters\n",
        "model.compile(optimizer=adam, loss='self_adversarial')\n",
        "\n",
        "# fit the model to data.\n",
        "model.fit(dataset['train'],\n",
        "             batch_size=1164,\n",
        "             epochs=10,\n",
        "             callbacks=[tensorboard_callback])\n",
        "\n",
        "# the training can be visualised using the following command:\n",
        "# tensorboard --logdir='./transe_train_logs' --port=8891\n",
        "# open the browser and go to the following URL: http://127.0.0.1:8891/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtvJZph731ob",
        "outputId": "36bb3f29-3cdf-4b67-c2f4-fcefd311b064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 30s 127ms/step - loss: 2054.4011\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 21s 90ms/step - loss: 1740.3618\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 1654.8723\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 21s 90ms/step - loss: 1613.1324\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 21s 91ms/step - loss: 1589.1139\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 22s 95ms/step - loss: 1572.5531\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 22s 92ms/step - loss: 1552.8732\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 21s 91ms/step - loss: 1546.3774\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 1541.0844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f61aeaa8640>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate on the test set\n",
        "ranks = model.evaluate(dataset['test'],\n",
        "                       batch_size=100,\n",
        "                       corrupt_side='o' # corrupt only the object\n",
        "                       )\n",
        "\n",
        "# import the evaluation metrics\n",
        "from ampligraph.evaluation.metrics import  hits_at_n_score, mr_score, mrr_score\n",
        "\n",
        "print('MR:', mr_score(ranks))\n",
        "print('MRR:', mrr_score(ranks)) #Le rang moyen est la position de classement moyenne des éléments prédits par le modèle parmi tous les éléments possibles.\n",
        "print('hits@10:', hits_at_n_score(ranks, 10))\n",
        "print('hits@5:', hits_at_n_score(ranks, 5))\n",
        "print('hits@3:', hits_at_n_score(ranks, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDChsvQp4CxD",
        "outputId": "87c0c72a-3cc3-4560-998c-95a15b7565d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206/206 [==============================] - 287s 1s/step\n",
            "MR: 652.9726000587142\n",
            "MRR: 0.10723492313397588\n",
            "hits@10: 0.29048830609648696\n",
            "hits@5: 0.21983560035228497\n",
            "hits@3: 0.16811821117526177\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}